- #Latency is the time it takes for a message, or a packet, to travel from its point of origin to the point of destination. #Latency, not bandwidth, is the performance bottleneck for most websites. 100-200 milliseconds in latency can be noticed laggy, 300 milliseconds as sluggish and 1000 milliseconds as very slow.
- The total latency between two machines is the sum of all the following delays
	- **Propagation delay** is the amount of time required for a message to travel from the sender to the receiver. This equals to distance between two machines over propagation speed of the signal. As current signals already propagate with more or less 200'000'000 m/s which is two thirds of the speed of light it is very hard to improve propagation delay.
	- **Transmission delay** is the amount of time required to push all packet's bits into the link. Here the packet's length and data-rate comes into play.
	- **Processing delay** is the amount of time required to process the packet header, check for bit-level errors, and determine the packet's destination. once the packet arrives at the router, the router must examine the packet header to determine the outgoing route and may run other checks on the data.
	- **Queuing delay** is the amount of time the packet is waiting in the queue until it can be processed. This occurs when a router does not have the capacity to process all incoming packets. Each packet not being processed is getting queued inside an incoming buffer.
- Last-Mile latency describes the fact that not long distances causes significant latencies but the last mile does. The reason why this happens is because the thousands of other signals around the sender and/or receiver have to be aggregated and routed by a local routing node provided by a local ISP. This can take tens of milliseconds.
-